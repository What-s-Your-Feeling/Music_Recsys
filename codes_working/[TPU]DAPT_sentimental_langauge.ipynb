{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fec7e8c6-6229-4475-b3f7-bca2c94209c7",
   "metadata": {},
   "source": [
    "### Install library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd33494c-7065-4f6e-8ef0-d623829fddd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers[sentencepiece]\n",
    "# !pip install openpyxl\n",
    "# !pip install pandas\n",
    "# !pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29f31aa-bb01-4dba-9b48-bd21043c1543",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0622f69e-ee28-4cdc-a935-70ada61945bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "random.seed(2022)\n",
    "torch.manual_seed(2022)\n",
    "np.random.seed(2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "432c0f8c-8ae7-4ad4-96d8-210137c99068",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-12 14:23:19.893678: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-12 14:23:20.065875: I tensorflow/core/tpu/tpu_initializer_helper.cc:262] Libtpu path is: libtpu.so\n",
      "I0912 14:23:20.181225316  959549 ev_epoll1_linux.cc:121]     grpc epoll fd: 66\n",
      "D0912 14:23:20.181242334  959549 ev_posix.cc:141]            Using polling engine: epoll1\n",
      "D0912 14:23:20.181279362  959549 lb_policy_registry.cc:48]   registering LB policy factory for \"grpclb\"\n",
      "D0912 14:23:20.181293728  959549 lb_policy_registry.cc:48]   registering LB policy factory for \"rls_experimental\"\n",
      "D0912 14:23:20.181299857  959549 lb_policy_registry.cc:48]   registering LB policy factory for \"priority_experimental\"\n",
      "D0912 14:23:20.181302521  959549 lb_policy_registry.cc:48]   registering LB policy factory for \"weighted_target_experimental\"\n",
      "D0912 14:23:20.181304781  959549 lb_policy_registry.cc:48]   registering LB policy factory for \"pick_first\"\n",
      "D0912 14:23:20.181307124  959549 lb_policy_registry.cc:48]   registering LB policy factory for \"round_robin\"\n",
      "D0912 14:23:20.181312241  959549 lb_policy_registry.cc:48]   registering LB policy factory for \"ring_hash_experimental\"\n",
      "D0912 14:23:20.181322338  959549 dns_resolver_ares.cc:545]   Using ares dns resolver\n",
      "D0912 14:23:20.181340089  959549 certificate_provider_registry.cc:39] registering certificate provider factory for \"file_watcher\"\n",
      "D0912 14:23:20.181345901  959549 lb_policy_registry.cc:48]   registering LB policy factory for \"cds_experimental\"\n",
      "D0912 14:23:20.181350987  959549 lb_policy_registry.cc:48]   registering LB policy factory for \"xds_cluster_impl_experimental\"\n",
      "D0912 14:23:20.181353827  959549 lb_policy_registry.cc:48]   registering LB policy factory for \"xds_cluster_resolver_experimental\"\n",
      "D0912 14:23:20.181356146  959549 lb_policy_registry.cc:48]   registering LB policy factory for \"xds_cluster_manager_experimental\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[percpu.cc : 535] RAW: rseq syscall failed with errno 22 after membarrier sycall succeeded.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer, AutoModelForMaskedLM\n",
    "from transformers import LineByLineTextDataset\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7d2281f-ab0a-4004-b904-48d9df88e704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12\n"
     ]
    }
   ],
   "source": [
    "# using TPU through torch\n",
    "import torch_xla\n",
    "import torch_xla.utils.utils as xu\n",
    "import torch_xla.core.xla_model as xm\n",
    "import torch_xla.utils.serialization as xser\n",
    "import torch_xla.distributed.parallel_loader as pl\n",
    "import torch_xla.distributed.xla_multiprocessing as xmp\n",
    "\n",
    "print(torch_xla.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4900a9-3448-4d54-b268-423307b9c45c",
   "metadata": {},
   "source": [
    "### TPU setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa8371f2-076f-4bc2-865d-69cc0345e9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## .py돌릴 때,\n",
    "#!export XRT_TPU_CONFIG=\"localservice;0;localhost:51011\"\n",
    "import os\n",
    "os.environ['XRT_TPU_CONFIG'] = \"localservice;0;localhost:51011\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08b99bfd-3518-4d70-879e-809dfadaadb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = xm.xla_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a00c752-682e-4c87-8920-bb06c9e55f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='xla', index=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fabc9b-a803-49b8-80e6-bf31545fad6d",
   "metadata": {},
   "source": [
    "### Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92c1da4b-a213-424b-9196-3889b44eaba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForMaskedLM.from_pretrained(\"klue/roberta-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38431540-fb21-49cc-b2a5-dba25eb801a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'>>>  KLUE_RoBERTa_large number of parameters : 337M'\n"
     ]
    }
   ],
   "source": [
    "klue_roberta_large_parameters = model.num_parameters() / 1_000_000\n",
    "print(f\"'>>>  KLUE_RoBERTa_large number of parameters : {round(klue_roberta_large_parameters)}M'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62aee184-4058-4213-a088-db3c2d4d4f81",
   "metadata": {},
   "source": [
    "### Load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "580e0afe-16cd-491d-b587-d8d96286dcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"klue/roberta-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7adbf449-2ac1-464c-b410-7083a763c734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaConfig {\n",
       "  \"_name_or_path\": \"klue/roberta-large\",\n",
       "  \"architectures\": [\n",
       "    \"RobertaForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 1024,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 4096,\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"max_position_embeddings\": 514,\n",
       "  \"model_type\": \"roberta\",\n",
       "  \"num_attention_heads\": 16,\n",
       "  \"num_hidden_layers\": 24,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"tokenizer_class\": \"BertTokenizer\",\n",
       "  \"transformers_version\": \"4.21.3\",\n",
       "  \"type_vocab_size\": 1,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 32000\n",
       "}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b05fb239-4821-411d-bc0e-47efe854598f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method PreTrainedTokenizerFast.tokenize of PreTrainedTokenizerFast(name_or_path='klue/roberta-large', vocab_size=32000, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '[CLS]', 'eos_token': '[SEP]', 'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f11db27-40eb-4df5-99e9-8528ee61ddb6",
   "metadata": {},
   "source": [
    "### Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a8fa1ce-ff38-4471-92aa-18052f43a4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82681\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>emotion</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>아내가 드디어 출산하게 되어서 정말 신이 나.</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>당뇨랑 합병증 때문에 먹어야 할 약이 열 가지가 넘어가니까 스트레스야.</td>\n",
       "      <td>긴장</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>고등학교에 올라오니 중학교 때보다 수업이 갑자기 어려워져서 당황스러워.</td>\n",
       "      <td>긴장</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>재취업이 돼서 받게 된 첫 월급으로 온 가족이 외식을 할 예정이야. 너무 행복해.</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>빚을 드디어 다 갚게 되어서 이제야 안도감이 들어.</td>\n",
       "      <td>평화</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         content emotion  label\n",
       "0                      아내가 드디어 출산하게 되어서 정말 신이 나.      기쁨      0\n",
       "1        당뇨랑 합병증 때문에 먹어야 할 약이 열 가지가 넘어가니까 스트레스야.      긴장      1\n",
       "2        고등학교에 올라오니 중학교 때보다 수업이 갑자기 어려워져서 당황스러워.      긴장      1\n",
       "3  재취업이 돼서 받게 된 첫 월급으로 온 가족이 외식을 할 예정이야. 너무 행복해.      기쁨      0\n",
       "4                   빚을 드디어 다 갚게 되어서 이제야 안도감이 들어.      평화      2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel(\"data_processing_re(82681).xlsx\")\n",
    "print(len(data))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa35dfcc-f0e2-4906-84dd-2585ca8589a8",
   "metadata": {},
   "source": [
    "### Preprocessing and Count by label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddf67364-ebc2-45f0-8fda-0f99c016ac5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()\n",
    "data.reset_index(drop=True,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31aff131-2513-4dd9-8142-9d1a88911b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pro = data[['content', 'label']]\n",
    "data_count = data[['content', 'emotion']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1780b8f-8948-4c7e-b697-9b79ccf0c5b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emotion</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>기쁨</th>\n",
       "      <td>11087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>긴장</th>\n",
       "      <td>20222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>분노</th>\n",
       "      <td>20541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>슬픔</th>\n",
       "      <td>23831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>중립</th>\n",
       "      <td>4827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>평화</th>\n",
       "      <td>2172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         content\n",
       "emotion         \n",
       "기쁨         11087\n",
       "긴장         20222\n",
       "분노         20541\n",
       "슬픔         23831\n",
       "중립          4827\n",
       "평화          2172"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_count.groupby(by=['emotion']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fbe8ada-549a-4e72-b5e9-090852f8ddb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pro = data_pro.iloc[:20000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e6a9d6b-4646-4773-ab0e-2589874f602e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_pro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d58eb56-1dde-4b1d-82ff-866f3bbde08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pro.to_csv('data_pro', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2670249a-a796-4bd8-9a2a-50127f702eea",
   "metadata": {},
   "source": [
    "### Build the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5794312b-4b2f-4430-9888-65dd00468576",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jyjy/.local/lib/python3.8/site-packages/transformers/data/datasets/language_modeling.py:121: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# default loading option = \"utf-8\"\n",
    "block_size = 512        # 256, 384, 512 \n",
    "dataset = LineByLineTextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=\"data_pro\",\n",
    "    block_size=block_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da532fae-7294-45b8-92fd-625c8376729a",
   "metadata": {},
   "source": [
    "### Define the data collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8061ed26-2a40-4b66-a7fe-496fac838ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b9e1f6-ab86-44b4-b284-a7db208b09a0",
   "metadata": {},
   "source": [
    "### Model to tpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ef1d1de-e33e-4f84-8545-1e62b7f12049",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408beb7f-8a3a-433d-83ba-428c2b33299b",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8402304a-8551-4d24-b09f-87ad17e5883b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "/home/jyjy/.local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 20001\n",
      "  Num Epochs = 40\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12500' max='12500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12500/12500 2:11:29, Epoch 39/40]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.653000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.375600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.295000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.241200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.195700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.148900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.107100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.077200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.035200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.997500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.970300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.948500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.918400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.889300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.856800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.845200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.823200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.797700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.787200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.768200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.758000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.739500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.727300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.729700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to test_mlm/64_512_20000_e8/checkpoint-500\n",
      "Configuration saved in test_mlm/64_512_20000_e8/checkpoint-500/config.json\n",
      "Model weights saved in test_mlm/64_512_20000_e8/checkpoint-500/pytorch_model.bin\n",
      "Saving model checkpoint to test_mlm/64_512_20000_e8/checkpoint-1000\n",
      "Configuration saved in test_mlm/64_512_20000_e8/checkpoint-1000/config.json\n",
      "Model weights saved in test_mlm/64_512_20000_e8/checkpoint-1000/pytorch_model.bin\n",
      "Saving model checkpoint to test_mlm/64_512_20000_e8/checkpoint-1500\n",
      "Configuration saved in test_mlm/64_512_20000_e8/checkpoint-1500/config.json\n",
      "Model weights saved in test_mlm/64_512_20000_e8/checkpoint-1500/pytorch_model.bin\n",
      "Deleting older checkpoint [test_mlm/64_512_20000_e8/checkpoint-500] due to args.save_total_limit\n",
      "Saving model checkpoint to test_mlm/64_512_20000_e8/checkpoint-2000\n",
      "Configuration saved in test_mlm/64_512_20000_e8/checkpoint-2000/config.json\n",
      "Model weights saved in test_mlm/64_512_20000_e8/checkpoint-2000/pytorch_model.bin\n",
      "Deleting older checkpoint [test_mlm/64_512_20000_e8/checkpoint-1000] due to args.save_total_limit\n",
      "Saving model checkpoint to test_mlm/64_512_20000_e8/checkpoint-2500\n",
      "Configuration saved in test_mlm/64_512_20000_e8/checkpoint-2500/config.json\n",
      "Model weights saved in test_mlm/64_512_20000_e8/checkpoint-2500/pytorch_model.bin\n",
      "Deleting older checkpoint [test_mlm/64_512_20000_e8/checkpoint-1500] due to args.save_total_limit\n",
      "Saving model checkpoint to test_mlm/64_512_20000_e8/checkpoint-3000\n",
      "Configuration saved in test_mlm/64_512_20000_e8/checkpoint-3000/config.json\n",
      "Model weights saved in test_mlm/64_512_20000_e8/checkpoint-3000/pytorch_model.bin\n",
      "Deleting older checkpoint [test_mlm/64_512_20000_e8/checkpoint-2000] due to args.save_total_limit\n",
      "Saving model checkpoint to test_mlm/64_512_20000_e8/checkpoint-3500\n",
      "Configuration saved in test_mlm/64_512_20000_e8/checkpoint-3500/config.json\n",
      "Model weights saved in test_mlm/64_512_20000_e8/checkpoint-3500/pytorch_model.bin\n",
      "Deleting older checkpoint [test_mlm/64_512_20000_e8/checkpoint-2500] due to args.save_total_limit\n",
      "Saving model checkpoint to test_mlm/64_512_20000_e8/checkpoint-4000\n",
      "Configuration saved in test_mlm/64_512_20000_e8/checkpoint-4000/config.json\n",
      "Model weights saved in test_mlm/64_512_20000_e8/checkpoint-4000/pytorch_model.bin\n",
      "Deleting older checkpoint [test_mlm/64_512_20000_e8/checkpoint-3000] due to args.save_total_limit\n",
      "Saving model checkpoint to test_mlm/64_512_20000_e8/checkpoint-4500\n",
      "Configuration saved in test_mlm/64_512_20000_e8/checkpoint-4500/config.json\n",
      "Model weights saved in test_mlm/64_512_20000_e8/checkpoint-4500/pytorch_model.bin\n",
      "Deleting older checkpoint [test_mlm/64_512_20000_e8/checkpoint-3500] due to args.save_total_limit\n",
      "Saving model checkpoint to test_mlm/64_512_20000_e8/checkpoint-5000\n",
      "Configuration saved in test_mlm/64_512_20000_e8/checkpoint-5000/config.json\n",
      "Model weights saved in test_mlm/64_512_20000_e8/checkpoint-5000/pytorch_model.bin\n",
      "Deleting older checkpoint [test_mlm/64_512_20000_e8/checkpoint-4000] due to args.save_total_limit\n",
      "Saving model checkpoint to test_mlm/64_512_20000_e8/checkpoint-5500\n",
      "Configuration saved in test_mlm/64_512_20000_e8/checkpoint-5500/config.json\n",
      "Model weights saved in test_mlm/64_512_20000_e8/checkpoint-5500/pytorch_model.bin\n",
      "Deleting older checkpoint [test_mlm/64_512_20000_e8/checkpoint-4500] due to args.save_total_limit\n",
      "Saving model checkpoint to test_mlm/64_512_20000_e8/checkpoint-6000\n",
      "Configuration saved in test_mlm/64_512_20000_e8/checkpoint-6000/config.json\n",
      "Model weights saved in test_mlm/64_512_20000_e8/checkpoint-6000/pytorch_model.bin\n",
      "Deleting older checkpoint [test_mlm/64_512_20000_e8/checkpoint-5000] due to args.save_total_limit\n",
      "Saving model checkpoint to test_mlm/64_512_20000_e8/checkpoint-6500\n",
      "Configuration saved in test_mlm/64_512_20000_e8/checkpoint-6500/config.json\n",
      "Model weights saved in test_mlm/64_512_20000_e8/checkpoint-6500/pytorch_model.bin\n",
      "Deleting older checkpoint [test_mlm/64_512_20000_e8/checkpoint-5500] due to args.save_total_limit\n",
      "Saving model checkpoint to test_mlm/64_512_20000_e8/checkpoint-7000\n",
      "Configuration saved in test_mlm/64_512_20000_e8/checkpoint-7000/config.json\n",
      "Model weights saved in test_mlm/64_512_20000_e8/checkpoint-7000/pytorch_model.bin\n",
      "Deleting older checkpoint [test_mlm/64_512_20000_e8/checkpoint-6000] due to args.save_total_limit\n",
      "Saving model checkpoint to test_mlm/64_512_20000_e8/checkpoint-7500\n",
      "Configuration saved in test_mlm/64_512_20000_e8/checkpoint-7500/config.json\n",
      "Model weights saved in test_mlm/64_512_20000_e8/checkpoint-7500/pytorch_model.bin\n",
      "Deleting older checkpoint [test_mlm/64_512_20000_e8/checkpoint-6500] due to args.save_total_limit\n",
      "Saving model checkpoint to test_mlm/64_512_20000_e8/checkpoint-8000\n",
      "Configuration saved in test_mlm/64_512_20000_e8/checkpoint-8000/config.json\n",
      "Model weights saved in test_mlm/64_512_20000_e8/checkpoint-8000/pytorch_model.bin\n",
      "Deleting older checkpoint [test_mlm/64_512_20000_e8/checkpoint-7000] due to args.save_total_limit\n",
      "Saving model checkpoint to test_mlm/64_512_20000_e8/checkpoint-8500\n",
      "Configuration saved in test_mlm/64_512_20000_e8/checkpoint-8500/config.json\n",
      "Model weights saved in test_mlm/64_512_20000_e8/checkpoint-8500/pytorch_model.bin\n",
      "Deleting older checkpoint [test_mlm/64_512_20000_e8/checkpoint-7500] due to args.save_total_limit\n",
      "Saving model checkpoint to test_mlm/64_512_20000_e8/checkpoint-9000\n",
      "Configuration saved in test_mlm/64_512_20000_e8/checkpoint-9000/config.json\n",
      "Model weights saved in test_mlm/64_512_20000_e8/checkpoint-9000/pytorch_model.bin\n",
      "Deleting older checkpoint [test_mlm/64_512_20000_e8/checkpoint-8000] due to args.save_total_limit\n",
      "Saving model checkpoint to test_mlm/64_512_20000_e8/checkpoint-9500\n",
      "Configuration saved in test_mlm/64_512_20000_e8/checkpoint-9500/config.json\n",
      "Model weights saved in test_mlm/64_512_20000_e8/checkpoint-9500/pytorch_model.bin\n",
      "Deleting older checkpoint [test_mlm/64_512_20000_e8/checkpoint-8500] due to args.save_total_limit\n",
      "Saving model checkpoint to test_mlm/64_512_20000_e8/checkpoint-10000\n",
      "Configuration saved in test_mlm/64_512_20000_e8/checkpoint-10000/config.json\n",
      "Model weights saved in test_mlm/64_512_20000_e8/checkpoint-10000/pytorch_model.bin\n",
      "Deleting older checkpoint [test_mlm/64_512_20000_e8/checkpoint-9000] due to args.save_total_limit\n",
      "Saving model checkpoint to test_mlm/64_512_20000_e8/checkpoint-10500\n",
      "Configuration saved in test_mlm/64_512_20000_e8/checkpoint-10500/config.json\n",
      "Model weights saved in test_mlm/64_512_20000_e8/checkpoint-10500/pytorch_model.bin\n",
      "Deleting older checkpoint [test_mlm/64_512_20000_e8/checkpoint-9500] due to args.save_total_limit\n",
      "Saving model checkpoint to test_mlm/64_512_20000_e8/checkpoint-11000\n",
      "Configuration saved in test_mlm/64_512_20000_e8/checkpoint-11000/config.json\n",
      "Model weights saved in test_mlm/64_512_20000_e8/checkpoint-11000/pytorch_model.bin\n",
      "Deleting older checkpoint [test_mlm/64_512_20000_e8/checkpoint-10000] due to args.save_total_limit\n",
      "Saving model checkpoint to test_mlm/64_512_20000_e8/checkpoint-11500\n",
      "Configuration saved in test_mlm/64_512_20000_e8/checkpoint-11500/config.json\n",
      "Model weights saved in test_mlm/64_512_20000_e8/checkpoint-11500/pytorch_model.bin\n",
      "Deleting older checkpoint [test_mlm/64_512_20000_e8/checkpoint-10500] due to args.save_total_limit\n",
      "Saving model checkpoint to test_mlm/64_512_20000_e8/checkpoint-12000\n",
      "Configuration saved in test_mlm/64_512_20000_e8/checkpoint-12000/config.json\n",
      "Model weights saved in test_mlm/64_512_20000_e8/checkpoint-12000/pytorch_model.bin\n",
      "Deleting older checkpoint [test_mlm/64_512_20000_e8/checkpoint-11000] due to args.save_total_limit\n",
      "Saving model checkpoint to test_mlm/64_512_20000_e8/checkpoint-12500\n",
      "Configuration saved in test_mlm/64_512_20000_e8/checkpoint-12500/config.json\n",
      "Model weights saved in test_mlm/64_512_20000_e8/checkpoint-12500/pytorch_model.bin\n",
      "Deleting older checkpoint [test_mlm/64_512_20000_e8/checkpoint-11500] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 7890.072662115097\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "batch_size = 64        # 8, 16, 32\n",
    "num_train_epochs = 8\n",
    "trained_model_path = f\"test_mlm/{batch_size}_{block_size}_20000_e8\"\n",
    "\n",
    "os.mkdir(trained_model_path)\n",
    "\n",
    "'''\n",
    "TrainingArguments parameters\n",
    "https://github.com/huggingface/transformers/blob/main/src/transformers/training_args.py\n",
    "'''\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=trained_model_path,\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=num_train_epochs,                 # total number of training epochs\n",
    "    per_device_train_batch_size=batch_size,      # batch size per device during training\n",
    "    save_total_limit=2,\n",
    "    weight_decay = 0.01,\n",
    "    tpu_num_cores = 85,\n",
    "    seed = 2022,\n",
    "    data_seed = 2022,\n",
    "    dataloader_pin_memory = True,\n",
    "    max_steps = 12_500\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "print(\"time :\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1f50a7-6d7a-4e31-a0ca-b4bcf96ab2f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f93741e-51a6-4f1c-abe5-12d300637c4a",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b2c7611-b81d-4ef1-9f9d-a5b345659fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to test_mlm/64_512_20000_e8\n",
      "Configuration saved in test_mlm/64_512_20000_e8/config.json\n",
      "Model weights saved in test_mlm/64_512_20000_e8/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(trained_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a48ec0b-9f02-4ac0-9ebe-38b3cae20ee4",
   "metadata": {},
   "source": [
    "#### The impact of Block size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1a9791-a0ef-43f2-a38e-54978561c7d8",
   "metadata": {},
   "source": [
    "| Block size | Epochs | Batch size | Total step | Loss | Time | Max. Mem |\n",
    "| - | - | - | - | - | - | - |\n",
    "| 256 | 2 | 16 | 10336 | 1.837 | 2h | 72G |\n",
    "| 384 | 2 | 16 | 10336 | 1.837 | 2h | 72G |\n",
    "| 512 | 2 | 16 | 10336 | 1.837 | 2h | 72G |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577f1935-fc40-4361-80b4-cb1a11a7f75f",
   "metadata": {},
   "source": [
    "#### The impact of Batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dea75e4-06c7-4a96-a36a-35d26a57f8a9",
   "metadata": {},
   "source": [
    "| Block size | Epochs | Batch size | Total step | Loss | Time | Max. MeM |\n",
    "| - | - | - | - | - | - | - |\n",
    "| 512 | 2 | 8 | 20672 | 1.8864  | 3h 15m | 67G |\n",
    "| 512 | 2 | 16 | 10336 | 1.837 | 2h | 72G |\n",
    "| 512 | 4 | 32 | 10336 | 1.6349 | 2h | 76G |\n",
    "| 512 | 8 | 32 | 12500 | 1.6068 | 2h 20m | 78G |\n",
    "| 512 | 8 | 64 | 10336 | | | hbm explo |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a05efc-443c-4a19-91e9-398edfcf9ee9",
   "metadata": {},
   "source": [
    "#### The impact of Data size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4750e417-c891-433c-9e7e-a5f4edf1b0b9",
   "metadata": {},
   "source": [
    "| Data size | Epochs | Batch size | Total step | Loss | Time | Max. MeM |\n",
    "| - | - | - | - | - | - | - |\n",
    "| 10000 | 8 | 64 | 12500 | 0.4174  | 2h 7m | 53G |\n",
    "| 20000 | 8 | 64 | 12500 | 0.7297  | 2h 20m | 54G  |\n",
    "|  |  |  |  |  |  |  |\n",
    "|  |  |  |  |  | |  |\n",
    "|  |  |  |  | | |   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2104df08-8885-46ed-8ecd-0aaec8715306",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f36bfc2-eec4-4253-90e4-bbbd4ce1e13d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
